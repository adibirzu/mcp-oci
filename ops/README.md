# MCP-OCI Observability Operations

This directory contains the complete observability stack for MCP-OCI servers, providing metrics, tracing, and profiling capabilities.

## ğŸš€ Quick Start

```bash
# Start the complete observability stack
./restart_observability_stack.sh

# Or start individual components
docker-compose up -d

# Start UX dashboard
./run-ux-local.sh
```

## ğŸ“Š Access Points

| Service | URL | Purpose | Credentials |
|---------|-----|---------|-------------|
| **Grafana** | http://localhost:3000 | Dashboards and visualization | admin/admin |
| **Prometheus** | http://localhost:9090 | Metrics collection and querying | - |
| **Tempo** | http://localhost:3200 | Distributed tracing backend | - |
| **Pyroscope** | http://localhost:4040 | Continuous profiling | - |
| **Jaeger** | http://localhost:16686 | Trace exploration and analysis | - |
| **UX Dashboard** | http://localhost:8010 | MCP servers status and control | - |

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MCP Servers (8001-8011)                 â”‚
â”‚  compute â”‚ db â”‚ network â”‚ security â”‚ cost â”‚ observability   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚ Metrics & Traces
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                OTLP Collector (4317/8889)                  â”‚
â”‚           Routes metrics and traces to backends            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚ Metrics                             â”‚ Traces
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Prometheus      â”‚                  â”‚  Tempo + Jaeger     â”‚
â”‚   (host network)  â”‚                  â”‚  (distributed trace) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                                     â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚    Grafana    â”‚
                â”‚  (localhost)  â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Configuration

### Network Setup
- **Prometheus**: Uses host networking mode for localhost target access
- **OTLP Collector**: Exports to both Tempo (HTTP) and Jaeger (gRPC)
- **All Services**: Configured with localhost endpoints for proper connectivity

### Port Mapping
- Prometheus: 9090 (host network)
- Grafana: 3000
- Tempo: 3200, 4318 (OTLP HTTP)
- Pyroscope: 4040, 7946
- Jaeger: 16686 (UI), 14317/14318 (OTLP), 14269 (metrics)
- OTLP Collector: 4317 (gRPC), 8889 (metrics)

## ğŸ§ª Testing & Validation

### End-to-End Test
```bash
# Comprehensive observability pipeline test
cd .. && python test_observability_e2e.py
```

### Generate Test Data
```bash
# Generate metrics (Prometheus format)
python generate_test_data.py --mode metrics

# Generate traces (OpenTelemetry)
python generate_test_data.py --mode traces

# Test all endpoints
python generate_test_data.py --mode test
```

### Health Checks
```bash
# Check container status
docker-compose ps

# Check service health
curl http://localhost:3000/api/health    # Grafana
curl http://localhost:9090/-/ready       # Prometheus
curl http://localhost:3200/api/echo      # Tempo
curl http://localhost:4040/              # Pyroscope
curl http://localhost:14269/             # Jaeger
curl http://localhost:8889/metrics       # OTLP Collector
```

## ğŸ› ï¸ Operations

### Start/Stop Services
```bash
# Complete restart with cleanup
./restart_observability_stack.sh

# Start services
docker-compose up -d

# Stop services
docker-compose down

# Stop with data cleanup
docker-compose down -v
```

### View Logs
```bash
# All services
docker-compose logs -f

# Specific service
docker-compose logs -f grafana
docker-compose logs -f prometheus
docker-compose logs -f otel-collector
```

### Scaling & Performance
```bash
# Check resource usage
docker stats

# Restart specific service
docker-compose restart grafana

# Update configuration and restart
docker-compose up -d --force-recreate grafana
```

## ğŸ” Troubleshooting

### Common Issues

1. **Prometheus targets down**
   - Check MCP servers are running: `scripts/mcp-launchers/start-mcp-server.sh status compute`
   - Verify localhost accessibility from host network

2. **OTLP Collector errors**
   - Check Tempo and Jaeger connectivity
   - Verify port mappings (no conflicts on 4317/4318)

3. **Grafana data source issues**
   - Verify localhost URLs in data source configuration
   - Check service connectivity from Grafana container

4. **Missing traces/metrics**
   - Confirm MCP servers have observability enabled
   - Check OTLP endpoint configuration: `OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317`

### Debug Commands
```bash
# Check network connectivity
docker-compose exec grafana curl http://localhost:9090/api/v1/targets
docker-compose exec grafana curl http://localhost:3200/api/echo

# Check OTLP collector configuration
docker-compose exec otel-collector cat /etc/otel-collector.yaml

# Restart problematic services
docker-compose restart otel-collector jaeger
```

## ğŸ“ File Structure

```
ops/
â”œâ”€â”€ docker-compose.yml              # Main observability stack
â”œâ”€â”€ restart_observability_stack.sh  # Complete restart script
â”œâ”€â”€ run-ux-local.sh                 # UX dashboard startup
â”œâ”€â”€ generate_test_data.py           # Test data generation
â”œâ”€â”€ grafana/
â”‚   â”œâ”€â”€ provisioning/
â”‚   â”‚   â”œâ”€â”€ datasources/            # Grafana data sources (localhost)
â”‚   â”‚   â””â”€â”€ dashboards/             # Dashboard configurations
â”‚   â””â”€â”€ dashboards/
â”‚       â””â”€â”€ mcp-observability.json  # MCP-specific dashboard
â”œâ”€â”€ prometheus/
â”‚   â””â”€â”€ prometheus.yml              # Prometheus configuration (localhost targets)
â”œâ”€â”€ tempo/
â”‚   â””â”€â”€ tempo.yaml                  # Tempo configuration
â”œâ”€â”€ pyroscope/
â”‚   â””â”€â”€ pyroscope.yaml              # Pyroscope configuration
â””â”€â”€ otel/
    â””â”€â”€ otel-collector.yaml         # OTLP collector configuration
```

## ğŸ“ˆ Available Metrics

### MCP Server Metrics
- `mcp_tool_calls_total` - Total tool invocations by server and tool
- `mcp_tool_duration_seconds` - Tool execution duration histogram
- `http_requests_total` - HTTP request counts
- `http_request_duration_seconds` - HTTP request duration

### Infrastructure Metrics
- `prometheus_*` - Prometheus internal metrics
- `otelcol_*` - OpenTelemetry collector metrics
- `grafana_*` - Grafana internal metrics

### Pre-configured Dashboards
- **MCP Observability**: Comprehensive MCP servers overview with tool metrics, success rates, and duration analysis
- **Service Health**: Infrastructure health monitoring
- **Request Analytics**: HTTP request patterns and performance

---

For detailed configuration and advanced usage, see the main project [README.md](../README.md).